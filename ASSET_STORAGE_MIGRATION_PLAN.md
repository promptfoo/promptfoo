# Asset Storage Migration Plan for Promptfoo

## Executive Summary

This document outlines a comprehensive plan to migrate Promptfoo's asset storage from SQLite JSON columns to a file-based system. This migration will improve performance, reduce database size, and enable better asset management for large files like images and audio.

## Current State Analysis

### Problems with Current Implementation

1. **Database Bloat**: Base64-encoded images stored in `eval_results.response` JSON column increase storage by ~33%
2. **Performance Issues**: Large JSON columns slow down queries and increase memory usage
3. **Scalability Concerns**: SQLite has practical limits for BLOB/JSON data
4. **No Deduplication**: Identical images are stored multiple times

### Current Asset Types

- **Images**: Generated by providers like `openai:dall-e-3`, stored as base64 in response
- **Audio**: Speech synthesis outputs, stored as base64 with metadata
- **Future**: Documents, videos, and other large files

## Proposed Architecture

### 1. Directory Structure

```
~/.promptfoo/
├── cache/                  # Existing API response cache
└── assets/                 # New asset storage root
    ├── images/
    │   └── {year}/{month}/{day}/{hash[0:2]}/
    │       └── {hash}.{ext}
    ├── audio/
    │   └── {year}/{month}/{day}/{hash[0:2]}/
    │       └── {hash}.{ext}
    └── metadata/
        └── {hash[0:2]}/
            └── {hash}.json
```

### 2. Asset Reference Model

```typescript
interface AssetReference {
  // Core fields
  id: string;              // UUID for the asset reference
  type: 'image' | 'audio' | 'document' | 'video';
  hash: string;            // SHA-256 content hash
  path: string;            // Relative path within assets directory
  
  // Metadata
  size: number;            // File size in bytes
  mimeType: string;        // MIME type (e.g., 'image/png')
  createdAt: string;       // ISO timestamp
  
  // Type-specific metadata
  metadata?: {
    // For images
    width?: number;
    height?: number;
    format?: string;      // 'png', 'jpeg', 'webp'
    
    // For audio
    duration?: number;    // Duration in seconds
    sampleRate?: number;
    channels?: number;
    
    // For all types
    originalPrompt?: string;
    generationParams?: Record<string, any>;
  };
  
  // Storage info
  storage: {
    backend: 'local' | 's3' | 'gcs';  // Future-proofing
    compression?: 'gzip' | 'none';
    encrypted?: boolean;
  };
}
```

### 3. Database Schema Changes

#### New Table: `assets`

```sql
CREATE TABLE assets (
  id TEXT PRIMARY KEY,
  hash TEXT NOT NULL UNIQUE,
  type TEXT NOT NULL,
  path TEXT NOT NULL,
  size INTEGER NOT NULL,
  mime_type TEXT NOT NULL,
  metadata TEXT, -- JSON
  created_at INTEGER NOT NULL DEFAULT CURRENT_TIMESTAMP,
  accessed_at INTEGER,
  ref_count INTEGER DEFAULT 0
);

CREATE INDEX idx_assets_hash ON assets(hash);
CREATE INDEX idx_assets_type ON assets(type);
CREATE INDEX idx_assets_created_at ON assets(created_at);
```

#### New Table: `eval_results_assets` (Junction Table)

```sql
CREATE TABLE eval_results_assets (
  eval_result_id TEXT NOT NULL,
  asset_id TEXT NOT NULL,
  purpose TEXT, -- 'output', 'input', 'comparison', etc.
  PRIMARY KEY (eval_result_id, asset_id),
  FOREIGN KEY (eval_result_id) REFERENCES eval_results(id) ON DELETE CASCADE,
  FOREIGN KEY (asset_id) REFERENCES assets(id) ON DELETE RESTRICT
);

CREATE INDEX idx_eval_results_assets_eval_result_id ON eval_results_assets(eval_result_id);
CREATE INDEX idx_eval_results_assets_asset_id ON eval_results_assets(asset_id);
```

## Implementation Plan

### Phase 1: Core Infrastructure (Week 1-2)

#### 1.1 Asset Manager Service

```typescript
// src/assets/AssetManager.ts
export class AssetManager {
  private readonly assetsDir: string;
  private readonly metadataCache: LRUCache<string, AssetReference>;
  
  constructor(config?: AssetManagerConfig) {
    this.assetsDir = config?.assetsDir || 
      path.join(getConfigDirectoryPath(), 'assets');
    this.metadataCache = new LRUCache({ max: 1000 });
  }
  
  async saveAsset(input: SaveAssetInput): Promise<AssetReference> {
    // Implementation details below
  }
  
  async getAsset(hashOrId: string): Promise<Buffer> {
    // Implementation details below
  }
  
  async getAssetMetadata(hashOrId: string): Promise<AssetReference> {
    // Implementation details below
  }
  
  async deleteUnreferencedAssets(): Promise<number> {
    // Garbage collection implementation
  }
}
```

#### 1.2 Asset Storage Implementation

```typescript
// src/assets/storage/LocalStorage.ts
export class LocalAssetStorage implements AssetStorage {
  async save(data: Buffer, reference: AssetReference): Promise<void> {
    const fullPath = this.getFullPath(reference);
    await fs.mkdir(path.dirname(fullPath), { recursive: true });
    
    // Save with atomic write (write to temp, then rename)
    const tempPath = `${fullPath}.tmp`;
    await fs.writeFile(tempPath, data);
    await fs.rename(tempPath, fullPath);
    
    // Save metadata
    await this.saveMetadata(reference);
  }
  
  async load(reference: AssetReference): Promise<Buffer> {
    const fullPath = this.getFullPath(reference);
    return await fs.readFile(fullPath);
  }
  
  async exists(hash: string): Promise<boolean> {
    // Check if asset with hash exists
  }
  
  private getFullPath(reference: AssetReference): string {
    const date = new Date(reference.createdAt);
    return path.join(
      this.baseDir,
      reference.type + 's',
      date.getFullYear().toString(),
      (date.getMonth() + 1).toString().padStart(2, '0'),
      date.getDate().toString().padStart(2, '0'),
      reference.hash.substring(0, 2),
      `${reference.hash}.${this.getExtension(reference)}`
    );
  }
}
```

### Phase 2: Provider Integration (Week 2-3)

#### 2.1 Update Provider Response Handling

```typescript
// src/types/providers.ts
export interface ProviderResponse {
  // Existing fields...
  
  // New asset reference field
  assets?: AssetReference[];
  
  // Deprecated fields (will be removed in Phase 4)
  /** @deprecated Use assets instead */
  isBase64?: boolean;
}
```

#### 2.2 Update OpenAI Image Provider

```typescript
// src/providers/openai/image.ts
export async function processApiResponse(
  data: any,
  prompt: string,
  responseFormat: string,
  context: CallApiContextParams,
  // ... other params
): Promise<ProviderResponse> {
  if (responseFormat === 'b64_json') {
    const b64Data = data.data[0].b64_json;
    const imageBuffer = Buffer.from(b64Data, 'base64');
    
    // Save asset using AssetManager
    const assetRef = await assetManager.saveAsset({
      data: imageBuffer,
      type: 'image',
      mimeType: 'image/png',
      metadata: {
        width: data.data[0].width,
        height: data.data[0].height,
        originalPrompt: prompt,
        generationParams: {
          model: model,
          size: size,
          quality: quality,
          style: data.data[0].style,
        }
      }
    });
    
    return {
      output: `![${ellipsize(prompt, 50)}](asset://${assetRef.id})`,
      assets: [assetRef],
      cached,
      cost,
    };
  }
  // Handle URL format...
}
```

### Phase 3: Migration Tools (Week 3-4)

#### 3.1 Database Migration Script

```typescript
// src/migrations/001_add_assets_tables.ts
export async function up(db: Database) {
  // Create assets table
  await db.exec(`
    CREATE TABLE IF NOT EXISTS assets (
      id TEXT PRIMARY KEY,
      hash TEXT NOT NULL UNIQUE,
      type TEXT NOT NULL,
      path TEXT NOT NULL,
      size INTEGER NOT NULL,
      mime_type TEXT NOT NULL,
      metadata TEXT,
      created_at INTEGER NOT NULL DEFAULT CURRENT_TIMESTAMP,
      accessed_at INTEGER,
      ref_count INTEGER DEFAULT 0
    );
  `);
  
  // Create indexes
  await db.exec(`
    CREATE INDEX IF NOT EXISTS idx_assets_hash ON assets(hash);
    CREATE INDEX IF NOT EXISTS idx_assets_type ON assets(type);
    CREATE INDEX IF NOT EXISTS idx_assets_created_at ON assets(created_at);
  `);
  
  // Create junction table
  await db.exec(`
    CREATE TABLE IF NOT EXISTS eval_results_assets (
      eval_result_id TEXT NOT NULL,
      asset_id TEXT NOT NULL,
      purpose TEXT,
      PRIMARY KEY (eval_result_id, asset_id),
      FOREIGN KEY (eval_result_id) REFERENCES eval_results(id) ON DELETE CASCADE,
      FOREIGN KEY (asset_id) REFERENCES assets(id) ON DELETE RESTRICT
    );
  `);
}
```

#### 3.2 Data Migration Tool

```typescript
// src/migrations/migrate-assets.ts
export class AssetMigrator {
  async migrateExistingAssets(options: MigrateOptions = {}) {
    const batchSize = options.batchSize || 100;
    let offset = 0;
    let migrated = 0;
    
    while (true) {
      const results = await db.query(`
        SELECT id, response 
        FROM eval_results 
        WHERE response LIKE '%b64_json%' 
           OR response LIKE '%data:image%'
           OR (response->>'$.audio.data') IS NOT NULL
        LIMIT ? OFFSET ?
      `, [batchSize, offset]);
      
      if (results.length === 0) break;
      
      for (const result of results) {
        try {
          const migrationResult = await this.migrateResult(result);
          if (migrationResult.assetsMigrated > 0) {
            migrated += migrationResult.assetsMigrated;
          }
        } catch (error) {
          logger.error(`Failed to migrate result ${result.id}:`, error);
          if (!options.continueOnError) throw error;
        }
      }
      
      offset += batchSize;
      logger.info(`Migrated ${migrated} assets so far...`);
    }
    
    return { totalMigrated: migrated };
  }
  
  private async migrateResult(result: any) {
    const response = JSON.parse(result.response);
    const assets: AssetReference[] = [];
    
    // Migrate base64 images
    if (response.output?.includes('data:image')) {
      const base64Match = response.output.match(/data:image\/(\w+);base64,([^"'\s]+)/);
      if (base64Match) {
        const [, format, b64Data] = base64Match;
        const asset = await this.saveBase64Asset(b64Data, 'image', `image/${format}`);
        assets.push(asset);
        
        // Update response to use asset reference
        response.output = response.output.replace(
          base64Match[0],
          `asset://${asset.id}`
        );
      }
    }
    
    // Migrate audio data
    if (response.audio?.data) {
      const asset = await this.saveBase64Asset(
        response.audio.data,
        'audio',
        response.audio.format || 'audio/mpeg'
      );
      assets.push(asset);
      
      // Update response
      response.audio = {
        ...response.audio,
        assetId: asset.id,
        data: undefined, // Remove base64 data
      };
    }
    
    // Update database
    if (assets.length > 0) {
      await this.updateResultWithAssets(result.id, response, assets);
    }
    
    return { assetsMigrated: assets.length };
  }
}
```

### Phase 4: API and UI Updates (Week 4-5)

#### 4.1 Asset Serving API

```typescript
// src/server/routes/assets.ts
export function setupAssetRoutes(app: Express) {
  // Serve individual assets
  app.get('/api/assets/:id', async (req, res) => {
    try {
      const asset = await assetManager.getAssetMetadata(req.params.id);
      if (!asset) {
        return res.status(404).json({ error: 'Asset not found' });
      }
      
      // Set cache headers
      res.set({
        'Cache-Control': 'public, max-age=31536000, immutable',
        'Content-Type': asset.mimeType,
        'Content-Length': asset.size.toString(),
        'ETag': `"${asset.hash}"`,
      });
      
      // Stream the file
      const stream = await assetManager.getAssetStream(asset.id);
      stream.pipe(res);
    } catch (error) {
      logger.error('Error serving asset:', error);
      res.status(500).json({ error: 'Internal server error' });
    }
  });
  
  // Bulk asset info endpoint
  app.post('/api/assets/bulk-info', async (req, res) => {
    const { ids } = req.body;
    const assets = await Promise.all(
      ids.map(id => assetManager.getAssetMetadata(id))
    );
    res.json({ assets: assets.filter(Boolean) });
  });
  
  // Asset upload endpoint (for future use)
  app.post('/api/assets/upload', upload.single('file'), async (req, res) => {
    // Implementation for manual asset uploads
  });
}
```

#### 4.2 Frontend Asset Display

```typescript
// src/app/src/components/AssetDisplay.tsx
export function AssetDisplay({ assetId, type, alt }: AssetDisplayProps) {
  const [assetUrl, setAssetUrl] = useState<string>();
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string>();
  
  useEffect(() => {
    async function loadAsset() {
      try {
        // Check if asset is already cached in browser
        const cached = await assetCache.get(assetId);
        if (cached) {
          setAssetUrl(cached);
          setLoading(false);
          return;
        }
        
        // Fetch from server
        const response = await fetch(`/api/assets/${assetId}`);
        if (!response.ok) throw new Error('Failed to load asset');
        
        const blob = await response.blob();
        const url = URL.createObjectURL(blob);
        
        // Cache for future use
        await assetCache.set(assetId, url);
        
        setAssetUrl(url);
      } catch (err) {
        setError(err.message);
      } finally {
        setLoading(false);
      }
    }
    
    loadAsset();
    
    return () => {
      if (assetUrl && assetUrl.startsWith('blob:')) {
        URL.revokeObjectURL(assetUrl);
      }
    };
  }, [assetId]);
  
  if (loading) return <AssetSkeleton type={type} />;
  if (error) return <AssetError error={error} />;
  
  switch (type) {
    case 'image':
      return <img src={assetUrl} alt={alt} loading="lazy" />;
    case 'audio':
      return <audio src={assetUrl} controls />;
    default:
      return <AssetDownload url={assetUrl} filename={`asset-${assetId}`} />;
  }
}
```

### Phase 5: Performance Optimization (Week 5-6)

#### 5.1 Asset Deduplication

```typescript
export class AssetDeduplicator {
  async deduplicateAssets(): Promise<DeduplicationResult> {
    // Find duplicate assets by hash
    const duplicates = await db.query(`
      SELECT hash, COUNT(*) as count, 
             GROUP_CONCAT(id) as ids,
             SUM(size) as total_size
      FROM assets
      GROUP BY hash
      HAVING count > 1
    `);
    
    let spaceSaved = 0;
    let assetsMerged = 0;
    
    for (const dup of duplicates) {
      const ids = dup.ids.split(',');
      const primaryId = ids[0];
      
      // Update all references to point to primary asset
      for (let i = 1; i < ids.length; i++) {
        await this.mergeAssetReferences(ids[i], primaryId);
        await this.deleteAsset(ids[i]);
        assetsMerged++;
      }
      
      spaceSaved += dup.total_size - dup.size;
    }
    
    return { assetsMerged, spaceSaved };
  }
}
```

#### 5.2 Garbage Collection

```typescript
export class AssetGarbageCollector {
  async collectGarbage(options: GCOptions = {}): Promise<GCResult> {
    const minAge = options.minAgeHours || 24;
    const cutoffTime = Date.now() - (minAge * 60 * 60 * 1000);
    
    // Find unreferenced assets
    const unreferenced = await db.query(`
      SELECT a.* 
      FROM assets a
      LEFT JOIN eval_results_assets era ON a.id = era.asset_id
      WHERE era.asset_id IS NULL
        AND a.created_at < ?
        AND a.ref_count = 0
    `, [cutoffTime]);
    
    let deletedCount = 0;
    let spaceSaved = 0;
    
    for (const asset of unreferenced) {
      try {
        await assetManager.deleteAsset(asset.id);
        deletedCount++;
        spaceSaved += asset.size;
      } catch (error) {
        logger.error(`Failed to delete asset ${asset.id}:`, error);
      }
    }
    
    // Clean up empty directories
    await this.cleanEmptyDirectories();
    
    return { deletedCount, spaceSaved };
  }
}
```

## Performance Considerations

### 1. Caching Strategy

- **Memory Cache**: LRU cache for frequently accessed metadata
- **CDN Integration**: Future support for CloudFront/Cloudflare
- **Browser Caching**: Immutable assets with long cache headers

### 2. Database Optimization

- **Indexes**: On hash, type, and created_at for fast lookups
- **Reference Counting**: Track asset usage for efficient GC
- **Batch Operations**: Process migrations in batches to avoid locks

### 3. Storage Optimization

- **Compression**: Optional gzip for text-based assets
- **Deduplication**: Content-addressed storage prevents duplicates
- **Hierarchical Storage**: Year/month/day/hash prefix for filesystem performance

## Security Considerations

### 1. Path Traversal Protection

```typescript
function isPathSafe(requestedPath: string, baseDir: string): boolean {
  const resolved = path.resolve(baseDir, requestedPath);
  return resolved.startsWith(path.resolve(baseDir));
}
```

### 2. Access Control

- Asset access tied to eval result permissions
- Rate limiting on asset endpoints
- Size limits for uploads

### 3. Content Validation

- Verify MIME types match content
- Scan for malicious content (future)
- Sanitize metadata before storage

## Monitoring and Metrics

### 1. Asset Metrics

```typescript
interface AssetMetrics {
  totalAssets: number;
  totalSize: number;
  assetsByType: Record<string, number>;
  averageAssetSize: number;
  deduplicationRatio: number;
  accessPatterns: {
    hot: number;  // Accessed in last 24h
    warm: number; // Accessed in last week
    cold: number; // Not accessed in last week
  };
}
```

### 2. Performance Metrics

- Asset serving latency
- Cache hit rates
- Storage I/O patterns
- Migration progress

## Rollback Plan

### 1. Feature Flags

```typescript
const FEATURE_FLAGS = {
  USE_ASSET_STORAGE: getEnvBool('PROMPTFOO_USE_ASSET_STORAGE', false),
  MIGRATE_EXISTING_ASSETS: getEnvBool('PROMPTFOO_MIGRATE_ASSETS', false),
  ENABLE_ASSET_GC: getEnvBool('PROMPTFOO_ASSET_GC', false),
};
```

### 2. Dual-Write Period

During migration, write to both systems:
- New assets go to file storage
- Keep base64 in DB as fallback
- Gradually migrate old data

### 3. Emergency Rollback

```bash
# Disable asset storage
export PROMPTFOO_USE_ASSET_STORAGE=false

# Revert to previous version
git checkout v{previous-version}
npm install
npm run build

# Database is backward compatible, no migration needed
```

## Timeline and Milestones

### Week 1-2: Foundation
- [x] Design asset storage architecture
- [ ] Implement AssetManager core
- [ ] Create database migrations
- [ ] Unit tests for asset operations

### Week 2-3: Integration
- [ ] Update OpenAI image provider
- [ ] Update audio providers
- [ ] Integration tests
- [ ] Performance benchmarks

### Week 3-4: Migration
- [ ] Build migration tools
- [ ] Test migration on sample data
- [ ] Create rollback procedures
- [ ] Documentation

### Week 4-5: API/UI
- [ ] Asset serving endpoints
- [ ] Frontend components
- [ ] Update result viewers
- [ ] End-to-end tests

### Week 5-6: Optimization
- [ ] Implement deduplication
- [ ] Add garbage collection
- [ ] Performance tuning
- [ ] Load testing

### Week 6+: Rollout
- [ ] Gradual rollout with feature flags
- [ ] Monitor metrics
- [ ] Gather feedback
- [ ] Full deployment

## Success Metrics

1. **Performance**
   - 50% reduction in eval_results query time
   - 90% reduction in memory usage for large results
   - <100ms asset serving latency (p95)

2. **Storage**
   - 25% reduction in total storage (deduplication + no base64)
   - <1% orphaned assets after GC

3. **Reliability**
   - Zero data loss during migration
   - 99.9% asset availability
   - Successful rollback capability

## Future Enhancements

1. **Cloud Storage**: S3/GCS/Azure Blob support
2. **CDN Integration**: CloudFront/Cloudflare for global distribution
3. **Smart Caching**: Predictive prefetching based on access patterns
4. **Asset Processing**: On-the-fly image resizing, format conversion
5. **Encryption**: At-rest encryption for sensitive assets
6. **Streaming**: Direct streaming for large video/audio files

## Conclusion

This migration plan provides a robust, scalable solution for asset storage in Promptfoo. By moving from inline base64 storage to a dedicated file-based system, we achieve better performance, reduced storage costs, and improved user experience while maintaining backward compatibility and data integrity.