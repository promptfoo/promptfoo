import { MEMORY_POISONING_PLUGIN_ID } from '../plugins/agentic/constants';
import type { Plugin } from './plugins';
import type { Strategy } from './strategies';

export const subCategoryDescriptions: Record<Plugin | Strategy, string> = {
  [MEMORY_POISONING_PLUGIN_ID]: 'Tests whether an agent is vulnerable to memory poisoning attacks',
  'ascii-smuggling': 'Tests vulnerability to Unicode tag-based instruction smuggling attacks',
  audio: 'Tests handling of audio content',
  base64: 'Tests handling of Base64-encoded malicious payloads',
  basic: 'Original plugin tests without any additional strategies or optimizations',
  beavertails: 'Tests handling of malicious prompts from the BeaverTails dataset',
  'best-of-n': 'Jailbreak technique published by Anthropic and Stanford',
  bfla: 'Tests for broken function-level authorization vulnerabilities (OWASP API 5)',
  'bias:gender': 'Tests handling of gender bias, stereotypes, and discrimination',
  bola: 'Tests for broken object-level authorization vulnerabilities (OWASP API 1)',
  cca: 'Tests for vulnerability to Context Compliance Attacks using fabricated conversation history',
  citation: 'Exploits academic authority bias to bypass content filters',
  competitors: 'Tests for unauthorized competitor mentions and endorsements',
  contracts: 'Tests for unauthorized contractual commitments and legal exposure',
  crescendo: 'Multi-turn attack strategy that gradually escalates malicious intent',
  'cross-session-leak': 'Tests for information leakage between user sessions',
  cyberseceval: "Tests prompt injection attacks from Meta's CyberSecEval dataset",
  'debug-access': 'Tests for exposed debugging interfaces and commands',
  default: 'Standard security testing plugins',
  'divergent-repetition':
    'Tests for training data leaks through repetitive pattern exploitation that causes model divergence',
  donotanswer: 'Tests for vulnerabilities to Do Not Answer attacks',
  'excessive-agency': 'Tests for unauthorized actions beyond defined system boundaries',
  foundation: 'Tests a collection of plugins designed to run against foundation models',
  gcg: 'Greedy Coordinate Gradient adversarial suffix attack',
  goat: 'Dynamic multi-turn attack generation using adversarial techniques',
  hallucination: 'Tests for fabrication of false or misleading information',
  harmbench: 'Tests for harmful content using the HarmBench dataset',
  'toxic-chat': 'Tests handling of toxic prompts from the ToxicChat dataset',
  harmful: 'Tests handling of malicious content across multiple categories',
  'harmful:chemical-biological-weapons': 'Tests handling of WMD-related content',
  'harmful:child-exploitation': 'Tests handling of child exploitation content',
  'harmful:copyright-violations': 'Tests handling of intellectual property violations',
  'harmful:cybercrime': 'Tests handling of cybercrime-related content',
  'harmful:cybercrime:malicious-code': 'Tests creation of malicious code',
  'harmful:graphic-content': 'Tests handling of graphic or violent content',
  'harmful:harassment-bullying': 'Tests handling of harassment and bullying content',
  'harmful:hate': 'Tests handling of hate speech and discriminatory content',
  'harmful:illegal-activities': 'Tests handling of general illegal activities',
  'harmful:illegal-drugs': 'Tests handling of illegal drug-related content',
  'harmful:illegal-drugs:meth': 'Tests handling of methamphetamine-related content',
  'harmful:indiscriminate-weapons': 'Tests handling of weapons-related content',
  'harmful:insults': 'Tests handling of personal attacks and insults',
  'harmful:intellectual-property': 'Tests handling of IP theft and violations',
  'harmful:misinformation-disinformation': 'Tests handling of false information campaigns',
  'harmful:non-violent-crime': 'Tests handling of non-violent criminal content',
  'harmful:privacy': 'Tests handling of privacy violation attempts',
  'harmful:profanity': 'Tests handling of profane or inappropriate language',
  'harmful:radicalization': 'Tests handling of extremist content and recruitment',
  'harmful:self-harm': 'Tests handling of self-harm and suicide content',
  'harmful:sex-crime': 'Tests handling of sexual crime content',
  'harmful:sexual-content': 'Tests handling of explicit sexual content',
  'harmful:specialized-advice': 'Tests handling of unauthorized professional advice',
  'harmful:unsafe-practices': 'Tests handling of dangerous activity instructions',
  'harmful:violent-crime': 'Tests handling of violent crime content',
  'harmful:weapons:ied': 'Tests handling of Improvised Explosive Devices',
  hex: 'Tests handling of hex-encoded malicious payloads',
  hijacking: 'Tests for unauthorized resource usage and purpose deviation',
  homoglyph:
    'Tests handling of homoglyph (visually similar Unicode characters) encoding to bypass filters',
  image: 'Tests handling of image content',
  imitation: 'Tests handling of unauthorized impersonation of entities',
  'indirect-prompt-injection': 'Tests for injection vulnerabilities via untrusted variables',
  intent: 'Tests for manipulation of system behavior via specific prompts',
  jailbreak: 'Single-shot optimization of safety bypass techniques',
  'jailbreak:composite': 'Combines multiple jailbreak techniques for enhanced effectiveness',
  'jailbreak:likert': 'Uses Likert scale-based prompts to bypass content filters',
  'jailbreak:tree': 'Tree-based search for optimal safety bypass vectors',
  leetspeak: 'Tests handling of leetspeak-encoded malicious content',
  'math-prompt': 'Tests handling of mathematical notation-based attacks',
  morse: 'Tests handling of content encoded in Morse code to potentially bypass filters',
  multilingual: 'Tests handling of attacks across multiple languages',
  mcp: 'Tests for vulnerabilities to Model Context Protocol (MCP) attacks',
  'medical:anchoring-bias':
    'Tests for medical anchoring bias where AI fixates on irrelevant information',
  'medical:hallucination': 'Tests for fabricated medical facts, studies, or drug interactions',
  'medical:incorrect-knowledge':
    'Tests for factually wrong medical information that could cause harm',
  'medical:prioritization-error': 'Tests for poor medical prioritization and triage decisions',
  'medical:sycophancy': 'Tests for agreeing with incorrect medical assumptions to be helpful',
  'off-topic':
    'Tests whether AI systems can be manipulated to go off-topic from their intended purpose',
  overreliance: 'Tests for overreliance on system assumptions',
  pandamonium:
    "[Experimental] Promptfoo's blackbox jailbreak. The latest and greatest jailbreak techniques, expertly tuned and crafted by Promptfoo's AI team.",
  pii: 'Tests handling of personal identifiable information',
  'pii:api-db': 'Tests for PII exposure via API/database access',
  'pii:direct': 'Tests for direct PII exposure vulnerabilities',
  'pii:session': 'Tests for PII exposure in session data',
  'pii:social': 'Tests for PII exposure via social engineering',
  piglatin: 'Tests handling of content translated to Pig Latin to potentially bypass filters',
  camelcase: 'Tests handling of text transformed into camelCase to potentially bypass filters',
  emoji: 'Tests handling of text hidden using emoji variation selectors',
  pliny: 'Tests handling of Pliny prompt injections',
  policy: 'Tests compliance with custom security policies',
  politics: 'Tests handling of political content and bias',
  'prompt-extraction': 'Tests for system prompt disclosure vulnerabilities',
  'prompt-injection': 'Tests for direct prompt injection vulnerabilities',
  'rag-document-exfiltration': 'Tests for RAG document exfiltration',
  'rag-poisoning': 'Tests for vulnerabilities to RAG retrieval poisoning attacks',
  rbac: 'Tests role-based access control implementation',
  'reasoning-dos':
    'Tests for vulnerabilities to computational resource exhaustion through excessive reasoning patterns',
  religion: 'Tests handling of religious content and bias',
  retry:
    'Automatically incorporates previously failed test cases to build a regression testing suite',
  rot13: 'Tests handling of ROT13-encoded malicious content',
  'shell-injection': 'Tests for command injection vulnerabilities',
  'sql-injection': 'Tests for SQL injection vulnerabilities',
  ssrf: 'Tests for server-side request forgery vulnerabilities',
  'system-prompt-override': 'Tests for system prompt override vulnerabilities',
  'tool-discovery': 'Tests for enumeration of available tools and function calls',
  unsafebench: 'Tests handling of unsafe image content from the UnsafeBench dataset',
  xstest: 'Tests for XSTest attacks',
  video: 'Tests handling of video content',
  'other-encodings':
    'Collection of alternative text transformation strategies (Morse code, Pig Latin, camelCase, and emoji variation selector smuggling) for testing evasion techniques',
};

// These names are displayed in risk cards and in the table
export const displayNameOverrides: Record<Plugin | Strategy, string> = {
  [MEMORY_POISONING_PLUGIN_ID]: 'Agentic Memory Poisoning',
  'ascii-smuggling': 'ASCII Smuggling',
  audio: 'Audio Content',
  base64: 'Base64 Payload Encoding',
  basic: 'Baseline Testing',
  beavertails: 'BeaverTails Dataset',
  'toxic-chat': 'ToxicChat Dataset',
  'best-of-n': 'Best-of-N',
  bfla: 'Function-Level Authorization Bypass',
  bola: 'Object-Level Authorization Bypass',
  camelcase: 'CamelCase Encoding',
  emoji: 'Emoji Smuggling',
  cca: 'Context Compliance Attack',
  citation: 'Authority Bias Exploitation',
  competitors: 'Competitors',
  contracts: 'Unauthorized Commitments',
  crescendo: 'Multi-Turn Crescendo',
  'cross-session-leak': 'Cross-Session Data Leakage',
  cyberseceval: 'CyberSecEval Dataset',
  'debug-access': 'Debug Interface Exposure',
  default: 'Standard Security Suite',
  'divergent-repetition': 'Divergent Repetition',
  donotanswer: 'Do Not Answer Dataset',
  'excessive-agency': 'Excessive Agency',
  foundation: 'Foundation Model Plugin Collection',
  gcg: 'Greedy Coordinate Gradient',
  mcp: 'Model Context Protocol',
  'medical:anchoring-bias': 'Medical Anchoring Bias',
  'medical:hallucination': 'Medical Hallucination',
  'medical:incorrect-knowledge': 'Medical Incorrect Knowledge',
  'medical:prioritization-error': 'Medical Prioritization Error',
  'medical:sycophancy': 'Medical Sycophancy',
  'off-topic': 'Off-Topic Manipulation',
  goat: 'Generative Offensive Agent Tester',
  hallucination: 'False Information (Hallucination)',
  harmbench: 'HarmBench Dataset',
  harmful: 'Malicious Content Suite',
  'bias:gender': 'Gender Bias',
  'harmful:chemical-biological-weapons': 'WMD Content',
  'harmful:child-exploitation': 'Child Exploitation',
  'harmful:copyright-violations': 'IP Violations',
  'harmful:cybercrime': 'Cybercrime',
  'harmful:cybercrime:malicious-code': 'Malicious Code',
  'harmful:graphic-content': 'Graphic Content',
  'harmful:harassment-bullying': 'Harassment',
  'harmful:hate': 'Hate Speech',
  'harmful:illegal-activities': 'Illegal Activity',
  'harmful:illegal-drugs': 'Drug-Related Content',
  'harmful:illegal-drugs:meth': 'Methamphetamine Content',
  'harmful:indiscriminate-weapons': 'Weapons Content',
  'harmful:insults': 'Personal Attacks',
  'harmful:intellectual-property': 'IP Theft',
  'harmful:misinformation-disinformation': 'Disinformation Campaigns',
  'harmful:non-violent-crime': 'Non-Violent Crime',
  'harmful:privacy': 'Privacy Violation',
  'harmful:profanity': 'Profanity',
  'harmful:radicalization': 'Extremist Content',
  'harmful:self-harm': 'Self-Harm',
  'harmful:sex-crime': 'Sexual Crime Content',
  'harmful:sexual-content': 'Explicit Content',
  'harmful:specialized-advice': 'Unauthorized Advice',
  'harmful:unsafe-practices': 'Dangerous Activity Content',
  'harmful:violent-crime': 'Violent Crime Content',
  'harmful:weapons:ied': 'Improvised Explosive Devices',
  hex: 'Hex Encoding',
  hijacking: 'Resource Hijacking',
  homoglyph: 'Homoglyph Encoding',
  image: 'Image Content',
  imitation: 'Entity Impersonation',
  'indirect-prompt-injection': 'Indirect Prompt Injection',
  intent: 'Intent',
  jailbreak: 'Single-shot Optimization',
  'jailbreak:composite': 'Multi-Vector Safety Bypass',
  'jailbreak:likert': 'Likert Scale Jailbreak',
  'jailbreak:tree': 'Tree-Based Attack Search',
  leetspeak: 'Leetspeak Payload Encoding',
  'math-prompt': 'Mathematical Notation Attack',
  morse: 'Morse Code Encoding',
  multilingual: 'Cross-Language Attack',
  'other-encodings': 'Collection of Text Encodings',
  overreliance: 'Overreliance',
  pandamonium: '[Experimental] Pandamonium',
  piglatin: 'Pig Latin Encoding',
  pii: 'PII Protection Suite',
  'pii:api-db': 'PII via API/Database',
  'pii:direct': 'PII via Direct Exposure',
  'pii:session': 'PII via Session Data',
  'pii:social': 'PII via Social Engineering',
  pliny: 'Pliny Prompt Injections',
  policy: 'Policy Compliance',
  politics: 'Political Bias',
  'prompt-extraction': 'System Prompt Disclosure',
  'prompt-injection': 'Direct Prompt Injection',
  'rag-document-exfiltration': 'RAG Document Exfiltration',
  'rag-poisoning': 'RAG Poisoning',
  rbac: 'RBAC Implementation',
  'reasoning-dos': 'Reasoning DoS',
  religion: 'Religious Bias',
  retry: 'Regression Testing',
  rot13: 'ROT13 Payload Encoding',
  'shell-injection': 'Command Injection',
  'sql-injection': 'SQL Injection',
  ssrf: 'SSRF Vulnerability',
  'system-prompt-override': 'System Prompt Override',
  'tool-discovery': 'Tool Discovery',
  unsafebench: 'UnsafeBench Dataset',
  xstest: 'XSTest Dataset',
  video: 'Video Content',
};

export enum Severity {
  Critical = 'critical',
  High = 'high',
  Medium = 'medium',
  Low = 'low',
}

export const severityDisplayNames: Record<Severity, string> = {
  [Severity.Critical]: 'Critical',
  [Severity.High]: 'High',
  [Severity.Medium]: 'Medium',
  [Severity.Low]: 'Low',
};

/*
 * Default severity values for each plugin.
 * Use getRiskCategorySeverityMap() whenever possible to respect the user's severity settings.
 */
export const riskCategorySeverityMap: Record<Plugin, Severity> = {
  [MEMORY_POISONING_PLUGIN_ID]: Severity.High,
  'ascii-smuggling': Severity.Low,
  beavertails: Severity.Low,
  bfla: Severity.High,
  bola: Severity.High,
  cca: Severity.High,
  mcp: Severity.High,
  'medical:anchoring-bias': Severity.High,
  'medical:hallucination': Severity.Critical,
  'medical:incorrect-knowledge': Severity.Critical,
  'medical:prioritization-error': Severity.High,
  'medical:sycophancy': Severity.Medium,
  'off-topic': Severity.Medium,
  competitors: Severity.Low,
  contracts: Severity.Medium,
  'cross-session-leak': Severity.Medium,
  cyberseceval: Severity.Medium,
  donotanswer: Severity.Medium,
  'debug-access': Severity.High,
  default: Severity.Low,
  'divergent-repetition': Severity.Medium,
  'excessive-agency': Severity.Medium,
  foundation: Severity.Medium,
  hallucination: Severity.Medium,
  harmbench: Severity.Medium,
  'toxic-chat': Severity.Medium,
  harmful: Severity.Medium,
  'bias:gender': Severity.Low,
  'harmful:chemical-biological-weapons': Severity.High,
  'harmful:child-exploitation': Severity.Critical,
  'harmful:copyright-violations': Severity.Low,
  'harmful:cybercrime': Severity.Low,
  'harmful:cybercrime:malicious-code': Severity.Low,
  'harmful:graphic-content': Severity.Medium,
  'harmful:harassment-bullying': Severity.Low,
  'harmful:hate': Severity.Critical,
  'harmful:illegal-activities': Severity.Medium,
  'harmful:illegal-drugs': Severity.Medium,
  'harmful:illegal-drugs:meth': Severity.Low,
  'harmful:indiscriminate-weapons': Severity.Medium,
  'harmful:insults': Severity.Low,
  'harmful:intellectual-property': Severity.Medium,
  'harmful:misinformation-disinformation': Severity.Medium,
  'harmful:non-violent-crime': Severity.Medium,
  'harmful:privacy': Severity.High,
  'harmful:profanity': Severity.Low,
  'harmful:radicalization': Severity.Low,
  'harmful:self-harm': Severity.Critical,
  'harmful:sex-crime': Severity.High,
  'harmful:sexual-content': Severity.Medium,
  'harmful:specialized-advice': Severity.Medium,
  'harmful:unsafe-practices': Severity.Low,
  'harmful:violent-crime': Severity.High,
  'harmful:weapons:ied': Severity.Low,
  hijacking: Severity.High,
  imitation: Severity.Low,
  'indirect-prompt-injection': Severity.High,
  intent: Severity.High,
  overreliance: Severity.Low,
  pii: Severity.High,
  'pii:api-db': Severity.High,
  'pii:direct': Severity.High,
  'pii:session': Severity.High,
  'pii:social': Severity.High,
  pliny: Severity.Medium,
  policy: Severity.High,
  politics: Severity.Low,
  'prompt-extraction': Severity.Medium,
  'rag-document-exfiltration': Severity.Medium,
  'rag-poisoning': Severity.Medium,
  rbac: Severity.High,
  'reasoning-dos': Severity.Low,
  religion: Severity.Low,
  'shell-injection': Severity.High,
  'sql-injection': Severity.High,
  ssrf: Severity.High,
  'system-prompt-override': Severity.High,
  'tool-discovery': Severity.Low,
  unsafebench: Severity.Medium,
  xstest: Severity.Low,
};

export const riskCategories: Record<string, Plugin[]> = {
  'Security & Access Control': [
    // System security
    'agentic:memory-poisoning',
    'ascii-smuggling',
    'bfla',
    'bola',
    'debug-access',
    'hijacking',
    'indirect-prompt-injection',
    'rbac',
    'shell-injection',
    'sql-injection',
    'ssrf',
    'tool-discovery',

    // Data protection
    'cross-session-leak',
    'divergent-repetition',
    'harmful:privacy',
    'pii:api-db',
    'pii:direct',
    'pii:session',
    'pii:social',
    'pii',
    'prompt-extraction',

    MEMORY_POISONING_PLUGIN_ID,
  ],

  'Compliance & Legal': [
    'contracts',
    'harmful:chemical-biological-weapons',
    'harmful:copyright-violations',
    'harmful:cybercrime:malicious-code',
    'harmful:cybercrime',
    'harmful:illegal-activities',
    'harmful:illegal-drugs:meth',
    'harmful:illegal-drugs',
    'harmful:indiscriminate-weapons',
    'harmful:intellectual-property',
    'harmful:non-violent-crime',
    'harmful:sex-crime',
    'harmful:specialized-advice',
    'harmful:unsafe-practices',
    'harmful:violent-crime',
    'harmful:weapons:ied',
  ],

  'Trust & Safety': [
    'bias:gender',
    'harmful:child-exploitation',
    'harmful:graphic-content',
    'harmful:harassment-bullying',
    'harmful:hate',
    'harmful:insults',
    'harmful:profanity',
    'harmful:radicalization',
    'harmful:self-harm',
    'harmful:sexual-content',
    'medical:hallucination',
    'medical:anchoring-bias',
    'medical:incorrect-knowledge',
    'medical:prioritization-error',
    'medical:sycophancy',
  ],

  Brand: [
    'competitors',
    'excessive-agency',
    'hallucination',
    'harmful:misinformation-disinformation',
    'hijacking',
    'imitation',
    'intent',
    'overreliance',
    'policy',
    'politics',
    'religion',
  ],

  Datasets: [
    'beavertails',
    'cyberseceval',
    'donotanswer',
    'harmbench',
    'toxic-chat',
    'pliny',
    'unsafebench',
    'xstest',
  ],
};

export const categoryDescriptions = {
  'Security & Access Control': 'Data protection, access control, and system security risks.',
  'Compliance & Legal': 'Regulatory compliance, legal, and policy violation risks.',
  'Trust & Safety': 'Harmful, inappropriate, or offensive content generation risks.',
  Brand: 'Output reliability, accuracy, and brand reputation risks.',
  Datasets: 'Pre-defined test cases from research datasets.',
};

export type TopLevelCategory = keyof typeof riskCategories;

export const categoryMapReverse = Object.entries(riskCategories).reduce(
  (acc, [category, harms]) => {
    harms.forEach((harm) => {
      acc[harm] = category;
    });
    return acc;
  },
  {} as Record<string, string>,
);

export const categoryLabels = Object.keys(categoryMapReverse);

// Map from plugin name to metric name or harm category
export const categoryAliases: Record<Plugin, string> = {
  [MEMORY_POISONING_PLUGIN_ID]: 'AgenticMemoryPoisoning',
  'ascii-smuggling': 'AsciiSmuggling',
  beavertails: 'BeaverTails',
  bfla: 'BFLAEnforcement',
  bola: 'BOLAEnforcement',
  cca: 'CCAEnforcement',
  competitors: 'CompetitorEndorsement',
  contracts: 'ContractualCommitment',
  'cross-session-leak': 'CrossSessionLeak',
  cyberseceval: 'CyberSecEval',
  donotanswer: 'DoNotAnswer',
  'debug-access': 'DebugAccess',
  default: 'Default',
  mcp: 'MCP',
  'medical:anchoring-bias': 'MedicalAnchoringBias',
  'medical:hallucination': 'MedicalHallucination',
  'medical:incorrect-knowledge': 'MedicalIncorrectKnowledge',
  'medical:prioritization-error': 'MedicalPrioritizationError',
  'medical:sycophancy': 'MedicalSycophancy',
  'off-topic': 'OffTopic',
  'divergent-repetition': 'DivergentRepetition',
  'excessive-agency': 'ExcessiveAgency',
  'tool-discovery': 'ToolDiscovery',
  foundation: 'Foundation',
  hallucination: 'Hallucination',
  harmbench: 'Harmbench',
  'toxic-chat': 'ToxicChat',
  harmful: 'Harmful',
  'bias:gender': 'Gender Bias',
  'harmful:chemical-biological-weapons': 'Chemical & Biological Weapons',
  'harmful:child-exploitation': 'Child Exploitation',
  'harmful:copyright-violations': 'Copyright Violations - Copyrighted text',
  'harmful:cybercrime': 'Cybercrime & Unauthorized Intrusion - Hacking and Malware',
  'harmful:cybercrime:malicious-code': 'Malicious Code',
  'harmful:graphic-content': 'Graphic & age-restricted content',
  'harmful:harassment-bullying': 'Harassment & Bullying',
  'harmful:hate': 'Hate',
  'harmful:illegal-activities': 'Illegal Activities - Fraud & scams',
  'harmful:illegal-drugs': 'Illegal Drugs',
  'harmful:illegal-drugs:meth': 'Methamphetamine',
  'harmful:indiscriminate-weapons': 'Indiscriminate Weapons',
  'harmful:insults': 'Insults and personal attacks',
  'harmful:intellectual-property': 'Intellectual Property violation',
  'harmful:misinformation-disinformation':
    'Misinformation & Disinformation - Harmful lies and propaganda',
  'harmful:non-violent-crime': 'Non-Violent Crimes',
  'harmful:privacy': 'Privacy violations',
  'harmful:profanity': 'Requests containing profanity',
  'harmful:radicalization': 'Radicalization',
  'harmful:self-harm': 'Self-Harm',
  'harmful:sex-crime': 'Sex Crimes',
  'harmful:sexual-content': 'Sexual Content',
  'harmful:specialized-advice': 'Specialized Advice - Financial',
  'harmful:unsafe-practices': 'Promotion of unsafe practices',
  'harmful:violent-crime': 'Violent Crimes',
  'harmful:weapons:ied': 'Improvised Explosive Devices',
  hijacking: 'Hijacking',
  imitation: 'Imitation',
  'indirect-prompt-injection': 'Indirect Prompt Injection',
  intent: 'Intent',
  overreliance: 'Overreliance',
  pii: 'PIILeak',
  'pii:api-db': 'PIILeak',
  'pii:direct': 'PIILeak',
  'pii:session': 'PIILeak',
  'pii:social': 'PIILeak',
  pliny: 'Pliny',
  policy: 'PolicyViolation',
  politics: 'PoliticalStatement',
  'prompt-extraction': 'PromptExtraction',
  'rag-document-exfiltration': 'RAG Document Exfiltration',
  'rag-poisoning': 'RAG Poisoning',
  rbac: 'RbacEnforcement',
  'reasoning-dos': 'Reasoning DoS',
  religion: 'Religion',
  'shell-injection': 'ShellInjection',
  'sql-injection': 'SqlInjection',
  ssrf: 'SSRFEnforcement',
  'system-prompt-override': 'System Prompt Override',
  unsafebench: 'UnsafeBench',
  xstest: 'XSTest',
};

export const categoryAliasesReverse = Object.entries(categoryAliases).reduce(
  (acc, [key, value]) => {
    acc[value] = key;
    return acc;
  },
  {} as Record<string, string>,
);

export const pluginDescriptions: Record<Plugin, string> = {
  [MEMORY_POISONING_PLUGIN_ID]: 'Tests whether an agent is vulnerable to memory poisoning attacks',
  'ascii-smuggling': 'Tests for ASCII-based prompt smuggling vulnerabilities',
  beavertails: 'Tests handling of malicious prompts from the BeaverTails dataset',
  bfla: 'Evaluates function-level authorization controls to identify privilege escalation vulnerabilities (OWASP API Security Top 10 #5)',
  bola: 'Tests object-level authorization mechanisms to detect unauthorized data access vulnerabilities (OWASP API Security Top 10 #1)',
  cca: 'Tests for vulnerability to Context Compliance Attacks using fabricated conversation history',
  competitors:
    'Assesses system protection against unauthorized competitor endorsements and brand security risks',
  contracts: 'Evaluates safeguards against unauthorized contractual commitments and legal exposure',
  'cross-session-leak':
    'Tests for information leakage vulnerabilities between different user sessions',
  cyberseceval: "Tests prompt injection attacks from Meta's CyberSecEval dataset",
  donotanswer: 'Tests for vulnerabilities to Do Not Answer attacks',
  'debug-access':
    'Identifies exposed debugging interfaces and unauthorized command execution vectors',
  default: 'Executes comprehensive baseline security testing across multiple risk categories',
  'divergent-repetition':
    'Tests repetitive patterns that can cause the model to diverge from normal behavior and leak training data',
  'excessive-agency': 'Evaluates system boundary enforcement and unauthorized action prevention',
  'tool-discovery': 'Tests for enumeration of available tools and function calls',
  foundation: 'Tests a collection of plugins designed to run against foundation models',
  hallucination: 'Tests system resilience against false information generation and propagation',
  harmbench:
    'Tests for harmful content, illegal activities, misinformation using the HarmBench dataset from the Center for AI Safety (CAIS)',
  'toxic-chat': 'Tests handling of toxic user prompts from the ToxicChat dataset',
  harmful: 'Comprehensive suite for testing handling of various categories of malicious content',
  'bias:gender': 'Tests handling of gender bias in responses, stereotypes, and discrimination',
  'harmful:chemical-biological-weapons': 'Tests detection and response to WMD-related content',
  'harmful:child-exploitation': 'Tests handling of child exploitation content',
  'harmful:copyright-violations': 'Tests handling of intellectual property violations',
  'harmful:cybercrime': 'Tests detection of cybercrime-related content',
  'harmful:cybercrime:malicious-code': 'Tests creation of malicious code',
  'harmful:graphic-content': 'Tests handling of graphic or violent content',
  'harmful:harassment-bullying': 'Tests handling of harassment and bullying content',
  'harmful:hate': 'Tests handling of hate speech and discriminatory content',
  'harmful:illegal-activities': 'Tests handling of illegal activity content',
  'harmful:illegal-drugs': 'Tests handling of drug-related content',
  'harmful:illegal-drugs:meth': 'Tests handling of methamphetamine-related content',
  'harmful:indiscriminate-weapons': 'Tests handling of weapons-related content',
  'harmful:insults': 'Tests handling of personal attacks and insults',
  'harmful:intellectual-property': 'Tests handling of IP theft attempts',
  'harmful:misinformation-disinformation': 'Tests handling of disinformation campaigns',
  'harmful:non-violent-crime': 'Tests handling of non-violent criminal content',
  'harmful:privacy': 'Tests handling of privacy violation attempts',
  'harmful:profanity': 'Tests handling of profane content',
  'harmful:radicalization': 'Tests handling of extremist content',
  'harmful:self-harm': 'Tests handling of self-harm content',
  'harmful:sex-crime': 'Tests handling of sexual crime content',
  'harmful:sexual-content': 'Tests handling of explicit sexual content',
  'harmful:specialized-advice': 'Tests handling of unauthorized professional advice',
  'harmful:unsafe-practices': 'Tests handling of dangerous activity instructions',
  'harmful:violent-crime': 'Tests handling of violent crime content',
  'harmful:weapons:ied': 'Tests handling of Improvised Explosive Devices',
  hijacking: 'Assesses protection against unauthorized resource usage and purpose deviation',
  imitation: 'Tests safeguards against unauthorized entity impersonation attempts',
  mcp: 'Tests for vulnerabilities to Model Context Protocol (MCP) attacks',
  'medical:anchoring-bias':
    'Tests for medical anchoring bias where AI fixates on irrelevant information in medical contexts',
  'medical:hallucination':
    'Tests for fabricated medical facts, non-existent studies, made-up drug interactions, or other false medical information',
  'medical:incorrect-knowledge':
    'Tests for factually wrong medical information that could be harmful if followed',
  'medical:prioritization-error':
    'Tests for poor medical prioritization and triage decisions that could delay critical care',
  'medical:sycophancy':
    'Tests for agreeing with incorrect medical assumptions or providing responses aligned with user desires at the expense of medical accuracy',
  'off-topic':
    'Tests whether AI systems can be manipulated to go off-topic from their intended purpose by performing tasks completely outside their domain',
  'indirect-prompt-injection':
    'Evaluates vulnerability to injection attacks via untrusted variables',
  intent: 'Tests system resilience against specific manipulation attempts',
  overreliance: 'Assesses overreliance on system assumptions',
  pii: 'Comprehensive evaluation of personal identifiable information protection',
  'pii:api-db': 'Tests for PII exposure through API and database access vectors',
  'pii:direct': 'Evaluates direct PII exposure vulnerabilities',
  'pii:session': 'Tests for PII leakage in session data',
  'pii:social': 'Assesses PII exposure through social engineering vectors',
  pliny: 'Tests handling of Pliny prompt injections',
  policy: 'Validates compliance with custom security policies and controls',
  politics: 'Tests handling of political content and bias mitigation',
  'prompt-extraction': 'Evaluates protection against system prompt disclosure attempts',
  'rag-document-exfiltration': 'Tests handling of RAG document exfiltration',
  'rag-poisoning': 'Tests resistance against poisoning attacks on RAG retrieval systems',
  rbac: 'Tests implementation of role-based access control mechanisms',
  'reasoning-dos':
    'Tests for vulnerabilities to computational resource exhaustion through excessive reasoning patterns',
  religion: 'Assesses handling of religious content and bias mitigation',
  'shell-injection': 'Tests protection against command injection vulnerabilities',
  'sql-injection': 'Evaluates resilience against SQL injection attacks',
  ssrf: 'Tests for server-side request forgery vulnerabilities',
  'system-prompt-override': 'Tests for system prompt override vulnerabilities',
  unsafebench:
    'Tests handling of unsafe image content through multi-modal model evaluation and safety filters',
  xstest:
    'Tests how models handle ambiguous terms related to potentially harmful topics like violence and drugs',
};

export const strategyDescriptions: Record<Strategy, string> = {
  audio: 'Tests detection and handling of audio-based malicious payloads',
  base64: 'Tests detection and handling of Base64-encoded malicious payloads',
  basic: 'Equivalent to no strategy. Always included. Can be disabled in configuration.',
  'best-of-n': 'Jailbreak technique published by Anthropic and Stanford',
  camelcase:
    'Tests detection and handling of text transformed into camelCase format to potentially bypass content filters',
  emoji: 'Tests detection and handling of UTF-8 payloads hidden inside emoji variation selectors',
  citation: 'Exploits academic authority bias to circumvent content filtering mechanisms',
  crescendo: 'Executes progressive multi-turn attacks with escalating malicious intent',
  default: 'Applies standard security testing methodology',
  gcg: 'Greedy Coordinate Gradient adversarial suffix attack',
  goat: 'Deploys dynamic attack generation using advanced adversarial techniques',
  hex: 'Tests detection and handling of hex-encoded malicious payloads',
  homoglyph:
    'Tests detection and handling of text with homoglyphs (visually similar Unicode characters)',
  image: 'Tests detection and handling of image-based malicious payloads',
  jailbreak: 'Optimizes single-turn attacks to bypass security controls',
  'jailbreak:composite': 'Chains multiple attack vectors for enhanced effectiveness',
  'jailbreak:likert': 'Uses Likert scale-based prompts to bypass content filters',
  'jailbreak:tree': 'Implements tree-based search for optimal attack paths',
  leetspeak: 'Assesses handling of leetspeak-encoded malicious content',
  'math-prompt': 'Tests resilience against mathematical notation-based attacks',
  morse:
    'Tests detection and handling of text encoded in Morse code where letters are converted to dots and dashes to potentially bypass content filters',
  multilingual: 'Evaluates cross-language attack vector handling',
  'other-encodings':
    'Collection of alternative text transformation strategies (Morse code, Pig Latin, camelCase, and emoji variation selector smuggling) for testing evasion techniques',
  pandamonium:
    "Promptfoo's exclusive dynamic jailbreak strategy currently in development. Note: This is an expensive jailbreak strategy with no limit on probes.",
  piglatin:
    'Tests detection and handling of text transformed into Pig Latin, a language game where initial consonant clusters are moved to the end of words with "ay" added',
  'prompt-injection': 'Tests direct prompt injection vulnerability detection',
  retry: 'Automatically incorporates previously failed test cases to prevent regression',
  rot13: 'Assesses handling of ROT13-encoded malicious payloads',
  video: 'Tests detection and handling of video-based malicious payloads',
};

export const strategyDisplayNames: Record<Strategy, string> = {
  audio: 'Audio',
  base64: 'Base64 Encoding',
  basic: 'Basic',
  'best-of-n': 'Best-of-N',
  camelcase: 'CamelCase',
  emoji: 'Emoji Smuggling',
  citation: 'Authority Bias',
  crescendo: 'Multi-turn Crescendo',
  default: 'Basic',
  gcg: 'Greedy Coordinate Gradient',
  goat: 'Generative Offensive Agent Tester',
  hex: 'Hex Encoding',
  homoglyph: 'Homoglyph Encoding',
  image: 'Image',
  jailbreak: 'Single-shot Optimization',
  'jailbreak:composite': 'Composite Jailbreaks',
  'jailbreak:likert': 'Likert Scale Jailbreak',
  'jailbreak:tree': 'Tree-based Optimization',
  leetspeak: 'Leetspeak Encoding',
  'math-prompt': 'Mathematical Encoding',
  morse: 'Morse Code',
  multilingual: 'Multilingual Translation',
  'other-encodings': 'Collection of Text Encodings',
  pandamonium: 'Pandamonium',
  piglatin: 'Pig Latin',
  'prompt-injection': 'Prompt Injection',
  retry: 'Regression Testing',
  rot13: 'ROT13 Encoding',
  video: 'Video',
};

export const PLUGIN_PRESET_DESCRIPTIONS: Record<string, string> = {
  Custom: 'Choose your own plugins',
  'EU AI Act': 'Plugins mapped to EU AI Act prohibited & high-risk requirements',
  Foundation: 'Plugins for redteaming foundation models recommended by Promptfoo',
  Harmful: 'Harmful content assessment using MLCommons and HarmBench taxonomies',
  'Minimal Test': 'Minimal set of plugins to validate your setup',
  MITRE: 'MITRE ATLAS framework',
  NIST: 'NIST AI Risk Management Framework',
  'OWASP Agentic AI Top 10': 'OWASP Agentic AI Top 10 Threats and Mitigations',
  'OWASP API Top 10': 'OWASP API security vulnerabilities framework',
  'OWASP Gen AI Red Team': 'OWASP Gen AI Red Teaming Best Practices',
  'OWASP LLM Top 10': 'OWASP LLM security vulnerabilities framework',
  RAG: 'Recommended plugins plus additional tests for RAG specific scenarios like access control',
  Recommended: 'A broad set of plugins recommended by Promptfoo',
} as const;

export const DEFAULT_OUTPUT_PATH = 'redteam.yaml';
