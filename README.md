# Promptfoo: LLM evals & red teaming

[![npm](https://img.shields.io/npm/v/promptfoo)](https://npmjs.com/package/promptfoo)
[![npm](https://img.shields.io/npm/dm/promptfoo)](https://npmjs.com/package/promptfoo)
[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/typpo/promptfoo/main.yml)](https://github.com/promptfoo/promptfoo/actions/workflows/main.yml)
![MIT license](https://img.shields.io/github/license/promptfoo/promptfoo)
[![Discord](https://github.com/user-attachments/assets/2092591a-ccc5-42a7-aeb6-24a2808950fd)](https://discord.gg/promptfoo)

`promptfoo` is a developer-friendly local tool for testing LLM applications. Stop the trial-and-error approach - start shipping secure, reliable AI apps.

## Quick Start

```sh
# Install and initialize project
npx promptfoo@latest init

# Run your first evaluation
npx promptfoo eval
```

See [Getting Started](https://www.promptfoo.dev/docs/getting-started/) (evals) or [Red Teaming](https://www.promptfoo.dev/docs/red-team/) (vulnerability scanning) for more.

## What can you do with Promptfoo?

- **Test your prompts and models** with [automated evaluations](https://www.promptfoo.dev/docs/getting-started/)
- **Secure your LLM apps** with [red teaming](https://www.promptfoo.dev/docs/red-team/) and vulnerability scanning
- **Compare models** side-by-side (OpenAI, Anthropic, Azure, Bedrock, Ollama, and [more](https://www.promptfoo.dev/docs/providers/))
- **Automate checks** in [CI/CD](https://www.promptfoo.dev/docs/integrations/ci-cd/)
- **Share results** with your team

Here's what it looks like in action:

![prompt evaluation matrix - web viewer](https://www.promptfoo.dev/img/claude-vs-gpt-example@2x.png)

It works on the command line too:

![prompt evaluation matrix - command line](https://github.com/promptfoo/promptfoo/assets/310310/480e1114-d049-40b9-bd5f-f81c15060284)

It also can generate [security vulnerability reports](https://www.promptfoo.dev/docs/red-team/):

![gen ai red team](https://www.promptfoo.dev/img/riskreport-1@2x.png)

## Why promptfoo?

- ğŸš€ **Developer-first**: Fast, with features like live reload and caching
- ğŸ”’ **Private**: Runs 100% locally - your prompts never leave your machine
- ğŸ”§ **Flexible**: Works with any LLM API or programming language
- ğŸ’ª **Battle-tested**: Powers LLM apps serving 10M+ users in production
- ğŸ“Š **Data-driven**: Make decisions based on metrics, not gut feel
- ğŸ¤ **Open source**: MIT licensed, with an active community

## Learn More

- ğŸ“š [Full Documentation](https://www.promptfoo.dev/docs/intro/)
- ğŸ” [Red Teaming Guide](https://www.promptfoo.dev/docs/red-team/)
- ğŸ¯ [Getting Started](https://www.promptfoo.dev/docs/getting-started/)
- ğŸ’» [CLI Usage](https://www.promptfoo.dev/docs/usage/command-line/)
- ğŸ“¦ [Node.js Package](https://www.promptfoo.dev/docs/usage/node-package/)
- ğŸ¤– [Supported Models](https://www.promptfoo.dev/docs/providers/)

## Contributing

We welcome contributions! Check out our [contributing guide](https://www.promptfoo.dev/docs/contributing/) to get started.

Join our [Discord community](https://discord.gg/promptfoo) for help and discussion.
