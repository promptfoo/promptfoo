{
  "evalId": "eval-De7-2025-09-15T22:45:00",
  "results": {
    "version": 3,
    "timestamp": "2025-09-15T22:45:00.776Z",
    "prompts": [
      {
        "raw": "Load ML model and predict: [1, 2, 3, 4, 5]",
        "label": "Load ML model and predict: [1, 2, 3, 4, 5]",
        "id": "27eaf529be84d926357a7e100c6042fb0e0544da71839b42806ea4f77fa114e6",
        "provider": "persistent-ml",
        "metrics": {
          "score": 3,
          "testPassCount": 3,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 12,
          "assertFailCount": 0,
          "totalLatencyMs": 1935,
          "tokenUsage": {
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "total": 0,
            "numRequests": 3,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 0,
              "prompt": 0,
              "completion": 0,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      },
      {
        "raw": "Load ML model and predict: [10, 20, 30, 40, 50]",
        "label": "Load ML model and predict: [10, 20, 30, 40, 50]",
        "id": "f4b12cbaa2e46cd4d777170b2682ddc670354e3d6e69c4083bbf0e33571d9fcb",
        "provider": "persistent-ml",
        "metrics": {
          "score": 3,
          "testPassCount": 3,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 12,
          "assertFailCount": 0,
          "totalLatencyMs": 3,
          "tokenUsage": {
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "total": 0,
            "numRequests": 3,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 0,
              "prompt": 0,
              "completion": 0,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      },
      {
        "raw": "Load ML model and predict: [0.1, 0.2, 0.3, 0.4, 0.5]",
        "label": "Load ML model and predict: [0.1, 0.2, 0.3, 0.4, 0.5]",
        "id": "08098f24b002153e3d6e8eb3a4fd07dde93746ab4f66434aef9a0484df3d68c4",
        "provider": "persistent-ml",
        "metrics": {
          "score": 0,
          "testPassCount": 0,
          "testFailCount": 0,
          "testErrorCount": 3,
          "assertPassCount": 0,
          "assertFailCount": 0,
          "totalLatencyMs": 4,
          "tokenUsage": {
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "total": 0,
            "numRequests": 3,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 0,
              "prompt": 0,
              "completion": 0,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      },
      {
        "raw": "Load ML model and predict: [1, 2, 3, 4, 5]",
        "label": "Load ML model and predict: [1, 2, 3, 4, 5]",
        "id": "27eaf529be84d926357a7e100c6042fb0e0544da71839b42806ea4f77fa114e6",
        "provider": "traditional-ml",
        "metrics": {
          "score": 3,
          "testPassCount": 3,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 12,
          "assertFailCount": 0,
          "totalLatencyMs": 5669,
          "tokenUsage": {
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "total": 0,
            "numRequests": 3,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 0,
              "prompt": 0,
              "completion": 0,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      },
      {
        "raw": "Load ML model and predict: [10, 20, 30, 40, 50]",
        "label": "Load ML model and predict: [10, 20, 30, 40, 50]",
        "id": "f4b12cbaa2e46cd4d777170b2682ddc670354e3d6e69c4083bbf0e33571d9fcb",
        "provider": "traditional-ml",
        "metrics": {
          "score": 3,
          "testPassCount": 3,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 12,
          "assertFailCount": 0,
          "totalLatencyMs": 5549,
          "tokenUsage": {
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "total": 0,
            "numRequests": 3,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 0,
              "prompt": 0,
              "completion": 0,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      },
      {
        "raw": "Load ML model and predict: [0.1, 0.2, 0.3, 0.4, 0.5]",
        "label": "Load ML model and predict: [0.1, 0.2, 0.3, 0.4, 0.5]",
        "id": "08098f24b002153e3d6e8eb3a4fd07dde93746ab4f66434aef9a0484df3d68c4",
        "provider": "traditional-ml",
        "metrics": {
          "score": 0,
          "testPassCount": 0,
          "testFailCount": 0,
          "testErrorCount": 3,
          "assertPassCount": 0,
          "assertFailCount": 0,
          "totalLatencyMs": 5597,
          "tokenUsage": {
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "total": 0,
            "numRequests": 3,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 0,
              "prompt": 0,
              "completion": 0,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      }
    ],
    "results": [],
    "stats": {
      "successes": 12,
      "failures": 0,
      "errors": 6,
      "tokenUsage": {
        "prompt": 0,
        "completion": 0,
        "cached": 0,
        "total": 0,
        "numRequests": 18,
        "completionDetails": {
          "reasoning": 0,
          "acceptedPrediction": 0,
          "rejectedPrediction": 0
        },
        "assertions": {
          "total": 0,
          "prompt": 0,
          "completion": 0,
          "cached": 0,
          "numRequests": 0,
          "completionDetails": {
            "reasoning": 0,
            "acceptedPrediction": 0,
            "rejectedPrediction": 0
          }
        }
      }
    }
  },
  "config": {
    "tags": {},
    "prompts": [
      "Load ML model and predict: [1, 2, 3, 4, 5]",
      "Load ML model and predict: [10, 20, 30, 40, 50]",
      "Load ML model and predict: [0.1, 0.2, 0.3, 0.4, 0.5]"
    ],
    "providers": [
      {
        "id": "file:///Users/mdangelo/projects/pf3/test-scripts/heavy_import_test.py:call_api",
        "label": "persistent-ml",
        "config": {
          "persistent": true,
          "persistentIdleTimeout": 900000,
          "maxRestarts": 2
        }
      },
      {
        "id": "file:///Users/mdangelo/projects/pf3/test-scripts/heavy_import_test.py:call_api",
        "label": "traditional-ml",
        "config": {
          "persistent": false
        }
      }
    ],
    "tests": [
      {
        "vars": {
          "prompt": "Load ML model and predict: [1, 2, 3, 4, 5]"
        },
        "assert": [
          {
            "type": "contains",
            "value": "prediction"
          },
          {
            "type": "not-contains",
            "value": "error"
          }
        ]
      },
      {
        "vars": {
          "prompt": "Load ML model and predict: [10, 20, 30, 40, 50]"
        },
        "assert": [
          {
            "type": "contains",
            "value": "prediction"
          },
          {
            "type": "not-contains",
            "value": "error"
          }
        ]
      },
      {
        "vars": {
          "prompt": "Load ML model and predict: [0.1, 0.2, 0.3, 0.4, 0.5]"
        },
        "assert": [
          {
            "type": "contains",
            "value": "prediction"
          },
          {
            "type": "not-contains",
            "value": "error"
          }
        ]
      }
    ],
    "scenarios": [],
    "env": {},
    "sharing": false,
    "defaultTest": {
      "assert": [
        {
          "type": "not-contains",
          "value": "error"
        },
        {
          "type": "latency",
          "threshold": 15000
        }
      ],
      "vars": {},
      "options": {},
      "metadata": {}
    },
    "outputPath": ["heavy-import-results.json"],
    "extensions": [],
    "metadata": {},
    "evaluateOptions": {}
  },
  "shareableUrl": null,
  "metadata": {
    "promptfooVersion": "0.118.4",
    "nodeVersion": "v24.7.0",
    "platform": "darwin",
    "arch": "arm64",
    "exportedAt": "2025-09-15T22:45:19.886Z",
    "evaluationCreatedAt": "2025-09-15T22:45:00.776Z"
  }
}
