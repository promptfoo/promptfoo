# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: G-Eval with vision-based grading using provider-specific rubric prompts

prompts:
  # OpenAI format
  - label: "OpenAI Vision"
    raw: |
      [
        {
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "Describe this image in detail, including all shapes, colors, and text:"
            },
            {
              "type": "image_url",
              "image_url": {
                "url": "data:image/png;base64,{{image}}"
              }
            }
          ]
        }
      ]

  # Anthropic format
  - label: "Anthropic Vision"
    raw: |
      [
        {
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "Describe this image in detail, including all shapes, colors, and text:"
            },
            {
              "type": "image",
              "source": {
                "type": "base64",
                "media_type": "image/png",
                "data": "{{image}}"
              }
            }
          ]
        }
      ]

  # Gemini format
  - label: "Gemini Vision"
    raw: |
      [
        {
          "role": "user",
          "parts": [
            {
              "text": "Describe this image in detail, including all shapes, colors, and text:"
            },
            {
              "inline_data": {
                "mime_type": "image/png",
                "data": "{{image}}"
              }
            }
          ]
        }
      ]

  # Nova format
  - label: "Nova Vision"
    raw: |
      [
        {
          "role": "user",
          "content": [
            {
              "text": "Describe this image in detail, including all shapes, colors, and text:"
            },
            {
              "image": {
                "format": "png",
                "source": {
                  "bytes": "{{image}}"
                }
              }
            }
          ]
        }
      ]

providers:
  - openai:gpt-4o-mini
  - openai:gpt-4o
  - bedrock:anthropic.claude-3-sonnet-20240229-v1:0
  - vertex:gemini-1.5-flash
  - bedrock:amazon.nova-pro-v1:0

tests:
  # Test 1: Standard G-Eval with automatic image inclusion
  - description: "Geometric shapes - automatic"
    vars:
      image: file://test-image.png
    assert:
      - type: g-eval
        value: >-
          Visual Accuracy - The description should correctly identify four geometric shapes
          (square, circle, triangle, star), their colors (blue, red, green, yellow),
          the "Test Shapes" title, and their 2x2 grid arrangement.
        threshold: 0.7
        provider: openai:gpt-4o-mini  # Vision model handles it automatically

  # Test 2: With custom YAML rubric
  - description: "Geometric shapes - YAML rubric"
    vars:
      image: file://test-image.png
    assert:
      - type: g-eval
        value: "Accurate identification of shapes, colors, and layout"
        threshold: 0.7
        provider: openai:gpt-4o-mini
        rubricPrompt: file://vision-rubrics/standard.yaml

  # Test 3: Multiple providers - all automatic
  - description: "Shapes - Anthropic"
    vars:
      image: file://test-image.png
    assert:
      - type: g-eval
        value: "Visual accuracy - shapes and colors"
        threshold: 0.7
        provider: bedrock:anthropic.claude-3-sonnet-20240229-v1:0

  - description: "Shapes - Gemini"
    vars:
      image: file://test-image.png
    assert:
      - type: g-eval
        value: "Visual accuracy - shapes and colors"
        threshold: 0.7
        provider: vertex:gemini-1.5-flash

  # Test 4: Chart analysis
  - description: "Bar chart test"
    vars:
      image: file://test-chart.png
    assert:
      - type: g-eval
        value: >-
          Chart Analysis - Identify chart type, title, products, and values
        threshold: 0.7
        provider: openai:gpt-4o-mini
