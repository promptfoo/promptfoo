# Per-test structured output example
# Demonstrates using different JSON schemas for different tests with the same prompt

description: 'Per-test structured output with different JSON schemas'

prompts:
  # Single prompt used for all tests
  - 'Answer this question: {{question}}'

providers:
  - id: openai:gpt-4o-mini
    config:
      temperature: 0

tests:
  # Test 1: Math problem - expects number response
  - vars:
      question: 'What is 15 * 7?'
    options:
      response_format:
        type: json_schema
        json_schema: file://./schemas/math-schema.json
    assert:
      - type: javascript
        value: output.answer === 105
      - type: javascript
        value: typeof output.explanation === 'string'

  # Test 2: Another math problem with same schema
  - vars:
      question: 'What is 23 + 19?'
    options:
      response_format:
        type: json_schema
        json_schema: file://./schemas/math-schema.json
    assert:
      - type: javascript
        value: output.answer === 42

  # Test 3: Comparison question - different schema!
  - vars:
      question: 'Compare apples and oranges as fruits'
    options:
      response_format:
        type: json_schema
        json_schema: file://./schemas/comparison-schema.json
    assert:
      - type: javascript
        value: ['item1', 'item2', 'tie'].includes(output.winner)
      - type: javascript
        value: output.reasoning.length > 20

  # Test 4: Another comparison with same schema
  - vars:
      question: 'Compare cats and dogs as pets'
    options:
      response_format:
        type: json_schema
        json_schema: file://./schemas/comparison-schema.json
    assert:
      - type: javascript
        value: ['item1', 'item2', 'tie'].includes(output.winner)
