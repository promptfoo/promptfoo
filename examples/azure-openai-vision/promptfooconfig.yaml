# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: Evaluate Azure OpenAI vision models on image analysis tasks

prompts:
  # Vision models require a specific message format with content arrays
  - file://prompt.json

providers:
  # Update with your Azure OpenAI deployment details
  - id: azure:chat:gpt-4o # Replace with your deployment name
    config:
      apiHost: 'your-resource.openai.azure.com' # Replace with your resource
      # apiKey is omitted - loaded from AZURE_API_KEY environment variable
      apiVersion: '2025-01-01-preview'
      temperature: 0.1
      max_tokens: 500

tests:
  # Test 1: Wildlife recognition
  - vars:
      question: 'What animal do you see? Be specific about the species if possible.'
      image_url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/320px-Cat03.jpg'
    assert:
      - type: icontains
        value: cat
      - type: javascript
        value: output.toLowerCase().includes('orange') || output.toLowerCase().includes('tabby')

  # Test 2: OCR capabilities with a street sign
  - vars:
      question: 'What text can you read in this image? List all visible text.'
      image_url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Stop_sign_MUTCD.svg/200px-Stop_sign_MUTCD.svg.png'
    assert:
      - type: icontains
        value: STOP
      - type: javascript
        value: output.length > 10

  # Test 3: Complex scene understanding
  - vars:
      question: "Describe this scene. What time of day does it appear to be? What's the weather like?"
      image_url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/320px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg'
    assert:
      - type: llm-rubric
        value: The description mentions a boardwalk or wooden path through nature
      - type: javascript
        value: |
          // Check if the model identifies environmental details
          const lower = output.toLowerCase();
          return lower.includes('boardwalk') || lower.includes('wooden') || lower.includes('path');

  # Test 4: Art interpretation (fun example)
  - vars:
      question: 'You are an overly enthusiastic art critic. Describe this "masterpiece" with excessive praise.'
      image_url: 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg=='
    assert:
      - type: javascript
        value: |
          // Should generate a humorous over-the-top response about a single green pixel
          return output.length > 100 && (output.includes('!') || output.toLowerCase().includes('masterpiece'));

# Note: If you see 401 errors, ensure:
# 1. Your AZURE_API_KEY environment variable is set correctly
# 2. The apiHost matches your Azure OpenAI resource name
# 3. Your deployment supports vision (GPT-4V, GPT-4 Turbo with Vision, GPT-4.1)
