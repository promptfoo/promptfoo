# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: Azure OpenAI vision model evaluation

prompts:
  # Vision models require a specific message format with content arrays
  - file://prompt.json

providers:
  # Update with your Azure OpenAI deployment details
  - id: azure:chat:gpt-4o
    config:
      apiHost: your-deployment.openai.azure.com
      apiVersion: 2024-02-15-preview
      temperature: 0.1
      max_tokens: 500

tests:
  # Test 1: Animal recognition (URL)
  - vars:
      question: What animal is this?
      image_url: https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/320px-Cat03.jpg
    assert:
      - type: contains
        value: cat

  # Test 2: OCR (local file)
  - vars:
      question: What does the sign say?
      image_url: file://assets/stop-sign.jpg
    assert:
      - type: contains
        value: STOP

  # Test 3: Scene description (local file)
  - vars:
      question: Describe this scene in one sentence.
      image_url: file://assets/landscape.jpg
    assert:
      - type: llm-rubric
        value: The description mentions a boardwalk or wooden path
# Note: If you see 401 errors, ensure:
# 1. Your AZURE_API_KEY environment variable is set correctly
# 2. The apiHost matches your Azure OpenAI resource name
# 3. Your deployment supports vision (GPT-4V, GPT-4 Turbo with Vision, GPT-4.1)
