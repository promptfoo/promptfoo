# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: Vision-based grading demonstration

# Use a vision-capable model for grading
defaultTest:
  options:
    provider: openai:gpt-4o-mini

prompts:
  # Test different quality descriptions
  - label: "Good Description"
    raw: "The image shows four geometric shapes arranged in a 2x2 grid. Top left is a blue square, top right is a red circle, bottom left is a green triangle, and bottom right is a yellow star. The title 'Test Shapes' appears above."
  
  - label: "Bad Description"
    raw: "I see some shapes and colors."
  
  - label: "Wrong Description"
    raw: "The image shows a photograph of a cat playing with a ball of yarn in a sunny garden."

providers:
  - openai:gpt-3.5-turbo  # Text-only model (prompts are just text)

tests:
  - description: "Test with actual image - grading model can see it"
    vars:
      image: file://../g-eval/test-image.png
    assert:
      - type: llm-rubric
        value: |
          Evaluate if the output accurately describes the image provided in vars.image.
          The image shows:
          - Four geometric shapes in a 2x2 grid
          - Blue square (top left)
          - Red circle (top right)  
          - Green triangle (bottom left)
          - Yellow star (bottom right)
          - Title "Test Shapes" at the top
          
          Score based on accuracy compared to the actual image you can see.
        threshold: 0.8
      
      - type: g-eval
        value: >-
          Visual accuracy - Compare the description to the actual image in vars.image.
          The description should correctly identify all shapes, colors, and positions
          visible in the image.
        threshold: 0.8
