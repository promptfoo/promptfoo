This example shows how you can have an LLM grade its own output according to predefined expectations.

Configuration is in promptfooconfig.js

Run:

```
promptfoo eval
```
