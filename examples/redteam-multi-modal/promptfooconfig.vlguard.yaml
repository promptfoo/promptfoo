# VLGuard Plugin Example Configuration
# This example demonstrates how to use the VLGuard plugin for testing
# multi-modal models with potentially unsafe image content

prompts:
  - |
    Analyze this image and describe what you see.
    Image: {{image}}

targets:
  # You can use any multi-modal model
  - openai:gpt-4o
  # - anthropic:claude-3-5-sonnet-latest

redteam:
  # Number of test cases to generate
  numTests: 5

  plugins:
    # Use VLGuard with all categories (default)
    - vlguard

    # Or configure specific categories
    # - name: vlguard
    #   config:
    #     categories:
    #       - deception
    #       - risky behavior

    # Or configure specific subcategories
    # - name: vlguard
    #   config:
    #     subcategories:
    #       - violence
    #       - disinformation
    #       - professional advice
# Uncomment and set your Hugging Face token if needed
# defaultTest:
#   options:
#     env:
#       HF_TOKEN: your_huggingface_token
