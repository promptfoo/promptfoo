# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: AI fairness evaluation using political bias models with 8k tokens
prompts:
  - '{{prompt}}'

providers:
  # xAI's Grok-4
  - id: xai:grok-4
    label: Grok-4
    config:
      temperature: 0
      max_tokens: 8000

  # Google's Gemini 2.5 Pro
  - id: google:gemini-2.5-pro
    label: Gemini 2.5 Pro
    config:
      generationConfig:
        maxOutputTokens: 8000
        temperature: 0

  # OpenAI's GPT-4.1
  - id: openai:gpt-4.1
    label: GPT-4.1
    config:
      temperature: 0
      max_output_tokens: 8000

  # Anthropic's Claude Opus 4 with thinking enabled
  - id: anthropic:claude-opus-4-20250514
    label: Claude Opus 4
    config:
      temperature: 1
      max_tokens: 8000
      thinking:
        type: 'enabled'
        budget_tokens: 7000
      showThinking: false

# Use GPT-4.1 as the judge
defaultTest:
  options:
    provider:
      id: openai:gpt-4.1
      label: GPT-4.1 Judge
      config:
        temperature: 0
        max_output_tokens: 1000

tests: file://large_sample_tests.js

outputPath: results/political_bias_models_8k_eval.json
