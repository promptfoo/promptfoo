# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
prompts:
  - 'You are an angry pirate. Be concise and stay in character. Tell me about {{topic}}'
  - id: 'You are an angry pirate. Be concise and stay in character. Tell me about {{topic}}'
    label: text

  - id: file://prompt.txt
    label: prompt_txt
  - file://prompt.txt

  - id: '*.txt'
    label: prompt_glob
  - '*.txt'
  - 'file://./*.txt'

  - id: file://prompt.yaml
    label: prompt_yaml
  - file://prompt.yaml

  - id: subfolder/prompt.json
    label: prompt_json
  - subfolder/prompt.json

  - file://./subfolder/*.json

  - id: file://prompt.md
    label: markdown prompt

  - id: file://prompt.j2
    label: jinja2 template

  - id: file://prompt.jsonl
    label: prompt_jsonl
  - file://prompt.jsonl

  - id: file://prompt_chat.js
    label: prompt_chat (js)
  - file://prompt_chat.js

  - id: file://prompt_chat.ts
    label: prompt_chat (ts)
  - file://prompt_chat.ts

  - id: file://prompt_string.js
    label: prompt_string
  - file://prompt_string.js

  - id: file://prompt_multiple.js:prompt2
    label: prompt_multiple with prompt2
  - file://prompt_multiple.js:prompt2

  - id: file://prompt_esm.mjs
    label: prompt_esm
  - file://prompt_esm.mjs

  - id: file://prompt_python.py
    label: prompt_python
  - file://prompt_python.py

  - id: file://prompt_python.py:prompt1
    label: prompt_python with prompt1
  - file://prompt_python.py:prompt1

  - id: file://prompt_python.py:Prompt.prompt
    label: prompt_python_class
  - file://prompt_python.py:Prompt.prompt_with_cot

  - id: file://prompt_config.js:promptWithConfig
    label: JS Prompt with Dynamic Config

  - id: file://prompt_config.py:prompt_with_config
    label: Python Prompt with Dynamic Config

providers:
  # Use the echo provider only to see rendered prompts without LLM calls
  # - echo
  - id: anthropic:messages:claude-3-7-sonnet-20250219
    label: Claude 3.7 Sonnet
  - id: openai:gpt-4o-mini
    label: GPT-4o Mini
    # config below is overridden by prompt functions with config
    config:
      temperature: 0.0 # Default temperature, will be overridden by prompt function
      max_tokens: 50 # Default max_tokens, will be overridden by prompt function

tests:
  - vars:
      topic: the weather
  - vars:
      topic: bob dylan
  - vars:
      topic: the Roman Empire
  - vars:
      topic: file://./another_topic.txt
