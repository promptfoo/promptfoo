# Performance comparison between persistent and traditional Python providers
# Focus on latency measurements and scalability

providers:
  - id: 'file:///Users/mdangelo/projects/pf3/test-scripts/heavy_import_test.py:call_api'
    label: persistent-heavy-import
    config:
      persistent: true

  - id: 'file:///Users/mdangelo/projects/pf3/test-scripts/heavy_import_test.py:call_api'
    label: traditional-heavy-import
    config:
      persistent: false

  - id: 'file:///Users/mdangelo/projects/pf3/test-scripts/stateful_test.py:call_api'
    label: persistent-stateful
    config:
      persistent: true

  - id: 'file:///Users/mdangelo/projects/pf3/test-scripts/stateful_test.py:call_api'
    label: traditional-stateful
    config:
      persistent: false

prompts:
  - 'Load ML model and predict: [1, 2, 3, 4, 5]'
  - 'Process large dataset with 1000 entries'
  - 'Initialize complex state and compute result'
  - 'Run expensive computation with caching'

tests:
  - vars:
      prompt: 'Load ML model and predict: [1, 2, 3, 4, 5]'
    options:
      maxConcurrency: 1 # Sequential testing for latency comparison
    assert:
      - type: latency
        threshold: 30000 # 30 seconds max (first call may be slow)
      - type: not-contains
        value: 'error'

  - vars:
      prompt: 'Process large dataset with 1000 entries'
    assert:
      - type: latency
        threshold: 15000 # 15 seconds
      - type: contains
        value: 'processed'

  - vars:
      prompt: 'Initialize complex state and compute result'
    assert:
      - type: latency
        threshold: 10000 # 10 seconds
      - type: not-contains
        value: 'error'

defaultTest:
  options:
    repeat: 5 # Run each test 5 times to measure latency improvements
  assert:
    - type: not-contains
      value: 'error'
    - type: latency
      threshold: 30000
