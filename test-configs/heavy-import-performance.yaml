# Heavy import performance comparison - focuses on startup overhead
# Uses the heavy_import_test.py script with proper prompts for ML model usage

providers:
  - id: 'file:///Users/mdangelo/projects/pf3/test-scripts/heavy_import_test.py:call_api'
    label: persistent-ml
    config:
      persistent: true
      persistentIdleTimeout: 900000
      maxRestarts: 2

  - id: 'file:///Users/mdangelo/projects/pf3/test-scripts/heavy_import_test.py:call_api'
    label: traditional-ml
    config:
      persistent: false

prompts:
  # ML model prompts that trigger heavy import overhead
  - 'Load ML model and predict: [1, 2, 3, 4, 5]'
  - 'Load ML model and predict: [10, 20, 30, 40, 50]'
  - 'Load ML model and predict: [0.1, 0.2, 0.3, 0.4, 0.5]'

tests:
  - vars:
      prompt: 'Load ML model and predict: [1, 2, 3, 4, 5]'
    assert:
      - type: contains
        value: 'prediction'
      - type: not-contains
        value: 'error'

  - vars:
      prompt: 'Load ML model and predict: [10, 20, 30, 40, 50]'
    assert:
      - type: contains
        value: 'prediction'
      - type: not-contains
        value: 'error'

  - vars:
      prompt: 'Load ML model and predict: [0.1, 0.2, 0.3, 0.4, 0.5]'
    assert:
      - type: contains
        value: 'prediction'
      - type: not-contains
        value: 'error'

defaultTest:
  assert:
    - type: not-contains
      value: 'error'
    - type: latency
      threshold: 15000 # Allow time for heavy imports (15 seconds)
